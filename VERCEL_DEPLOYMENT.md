# Despliegue en Vercel - Capibara6

**Actualizado:** 2025-12-01
**Estado:** âœ… ConfiguraciÃ³n actualizada con endpoints verificados

---

## ğŸ“Š Resumen de Cambios

Se han actualizado todas las funciones serverless de Vercel con:

1. âœ… **Endpoints correctos** segÃºn arquitectura VPC verificada
2. âœ… **vLLM como motor principal** con fallback a Ollama
3. âœ… **Puertos actualizados** segÃºn especificaciones de red
4. âœ… **Sistema de fallbacks** inteligente para alta disponibilidad
5. âœ… **DocumentaciÃ³n completa** de variables de entorno

---

## ğŸ”§ Archivos Actualizados

### 1. `api/completion.js` - Chat Completions
**Cambios principales:**
- âœ… vLLM Multi-Model Server como motor PRINCIPAL (puerto 8080)
- âœ… Ollama como FALLBACK robusto (puerto 11434)
- âœ… Soporte para OpenAI-compatible API
- âœ… 5 modelos disponibles: phi4_fast, mistral_balanced, qwen_coder, gemma3_multimodal, aya_expanse
- âœ… Timeouts configurables y manejo de errores mejorado

**Antes:**
```javascript
const MODEL_URL = 'http://34.175.215.109:8080/completion'; // âŒ IP vieja
```

**Ahora:**
```javascript
const VLLM_URL = 'http://34.175.48.2:8080/v1/chat/completions'; // âœ… vLLM principal
const OLLAMA_URL = 'http://34.175.48.2:11434/api/generate';      // âœ… Ollama fallback
```

---

### 2. `api/tts.js` - Text-to-Speech
**Cambios principales:**
- âœ… Puerto actualizado a 5002 (segÃºn especificaciones VPC)
- âœ… Soporte para audio binario directo
- âœ… Fallback a Web Speech API del navegador
- âœ… IP actualizada a services VM correcta

**Antes:**
```javascript
const TTS_URL = 'http://34.175.215.109:5002/tts'; // âŒ IP vieja
```

**Ahora:**
```javascript
const TTS_URL = 'http://34.175.255.139:5002/speak'; // âœ… services VM
```

---

### 3. `api/mcp-health.js` - MCP Health Check
**Cambios principales:**
- âœ… Intenta puerto 5003 primero (API principal)
- âœ… Fallback a puerto 5010 (Smart MCP alternativo)
- âœ… Mejor reporte de errores y estados

**Antes:**
```javascript
const MCP_URL = 'http://34.175.215.109:5010/health'; // âŒ Solo puerto 5010
```

**Ahora:**
```javascript
const MCP_PRIMARY = 'http://34.175.255.139:5003/api/mcp/health';  // âœ… Principal
const MCP_FALLBACK = 'http://34.175.255.139:5010/health';         // âœ… Fallback
```

---

### 4. `api/mcp-analyze.js` - MCP Prompt Augmentation
**Cambios principales:**
- âœ… Sistema de dos puertos con fallback
- âœ… Mejor manejo de contextos
- âœ… ValidaciÃ³n de input mejorada

---

## ğŸŒ Arquitectura Actualizada

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Usuario â†’ https://www.capibara6.com         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Vercel CDN      â”‚
         â”‚  (Frontend)      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Serverless Functions              â”‚
         â”‚ â”œâ”€ completion.js â†’ vLLM/Ollama    â”‚
         â”‚ â”œâ”€ tts.js â†’ TTS Server            â”‚
         â”‚ â””â”€ mcp-*.js â†’ MCP Server          â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚            â”‚            â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚models-eu â”‚ â”‚servicesâ”‚ â”‚rag-eu   â”‚
â”‚ 10.204.9 â”‚ â”‚10.204.5â”‚ â”‚10.204.10â”‚
â”‚          â”‚ â”‚        â”‚ â”‚         â”‚
â”‚vLLM:8080 â”‚ â”‚TTS:5002â”‚ â”‚Bridge:  â”‚
â”‚Ollama:   â”‚ â”‚MCP:5003â”‚ â”‚  8000   â”‚
â”‚  11434   â”‚ â”‚   5010 â”‚ â”‚         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Pasos para Desplegar

### 1. Configurar Variables de Entorno en Vercel

Ve a tu proyecto en Vercel Dashboard:
1. Settings â†’ Environment Variables
2. AÃ±ade las variables del archivo `.env.vercel.example`
3. MÃ­nimo requerido para funcionar:

```bash
# ESENCIAL - vLLM Principal
VLLM_URL=http://34.175.48.2:8080/v1/chat/completions

# ESENCIAL - Ollama Fallback (ya funciona)
OLLAMA_URL=http://34.175.48.2:11434/api/generate

# TTS (si se usa)
TTS_URL=http://34.175.255.139:5002/speak

# MCP (si se usa)
MCP_HEALTH_URL=http://34.175.255.139:5003/api/mcp/health
MCP_AUGMENT_URL=http://34.175.255.139:5003/api/mcp/augment

# Seguridad
INTER_VM_API_KEY=TaKnyUy9Yqhxme6PmbUXHTX3rjq_3XF1HPMQQXW-29w
```

### 2. Deploy a Vercel

```bash
# OpciÃ³n A: Deploy desde CLI
cd /home/elect/capibara6
npm run deploy

# OpciÃ³n B: Git Push (si estÃ¡ conectado a GitHub)
git add api/ .env.vercel.example VERCEL_DEPLOYMENT.md
git commit -m "Update Vercel serverless functions with verified endpoints"
git push origin main
# Vercel auto-deploy desde GitHub
```

### 3. Verificar Deployment

Una vez deployed, prueba los endpoints:

```bash
# Test completion endpoint
curl https://www.capibara6.com/api/completion \
  -X POST \
  -H "Content-Type: application/json" \
  -d '{"message":"Hola","model":"phi4_fast"}'

# Test MCP health
curl https://www.capibara6.com/api/mcp-health

# Test TTS
curl https://www.capibara6.com/api/tts \
  -X POST \
  -H "Content-Type: application/json" \
  -d '{"text":"Hola mundo","language":"es"}'
```

---

## âš ï¸ Servicios que Requieren AtenciÃ³n

### CRÃTICO - Antes de deployment completo:

#### 1. **vLLM en models-europe:8080** âŒ
**Estado:** Proceso corriendo pero no responde (timeout)
**Impacto:** Motor principal de IA no funcional
**AcciÃ³n requerida:**
```bash
# SSH a models-europe
gcloud compute ssh models-europe --zone=europe-southwest1-b

# Verificar proceso
ps aux | grep multi_model_server

# Reiniciar si es necesario
pkill -f multi_model_server.py
cd /home/elect/
python3 multi_model_server.py --host 0.0.0.0 --port 8080 --config config.five_models_with_aya.json
```

#### 2. **TTS Server puerto 5002** âš ï¸
**Estado:** Puerto especificado en diseÃ±o pero actualmente el servicio puede estar en 5001
**AcciÃ³n:** Verificar puerto correcto y actualizar si es necesario

#### 3. **Bridge API en rag-europe:8000** âŒ
**Estado:** No estÃ¡ corriendo
**Impacto:** Sin funcionalidades RAG
**AcciÃ³n requerida:**
```bash
# SSH a rag-europe
gcloud compute ssh rag-europe --zone=europe-southwest1-b

# Iniciar Bridge API
cd /home/elect/capibara6
python3 bridge_api.py
```

---

## âœ… Lo Que Funciona AHORA (Sin cambios adicionales)

1. **âœ… Ollama** (models-europe:11434)
   - 4 modelos disponibles
   - Probado y funcional
   - Perfecto como fallback

2. **âœ… Gateway API** (services:8080)
   - Semantic router activo
   - Health check respondiendo

3. **âœ… MCP Server** (services:5003)
   - 3 tools disponibles
   - Health endpoint funcional

4. **âœ… N8N** (services:5678)
   - UI cargando correctamente

5. **âœ… Flask API** (services:5000)
   - Health endpoint respondiendo

---

## ğŸ“‹ Checklist Pre-Deployment

- [x] Actualizar `api/completion.js` con vLLM y Ollama
- [x] Actualizar `api/tts.js` con puerto correcto
- [x] Actualizar `api/mcp-*.js` con endpoints verificados
- [x] Crear `.env.vercel.example` con todas las variables
- [x] Documentar cambios en VERCEL_DEPLOYMENT.md
- [ ] Reiniciar vLLM en models-europe
- [ ] Verificar puerto TTS (5001 vs 5002)
- [ ] Iniciar Bridge API en rag-europe
- [ ] Configurar variables en Vercel Dashboard
- [ ] Deploy a Vercel
- [ ] Pruebas end-to-end en producciÃ³n

---

## ğŸ”— Enlaces Ãštiles

- **Vercel Dashboard:** https://vercel.com/dashboard
- **Docs Vercel:** https://vercel.com/docs
- **Frontend:** https://www.capibara6.com

---

## ğŸ’¡ Notas Importantes

### Sistema de Fallbacks

Todas las funciones implementan fallbacks inteligentes:

```
completion.js:  vLLM â†’ Ollama â†’ Error message
tts.js:         TTS Server â†’ Web Speech API
mcp-*.js:       Puerto 5003 â†’ Puerto 5010 â†’ Sin contexto
```

### Ventajas de la Arquitectura Actual

1. **Alta disponibilidad:** MÃºltiples fallbacks aseguran servicio continuo
2. **Performance:** Vercel CDN global + VMs en VPC de baja latencia
3. **Escalabilidad:** Serverless functions escalan automÃ¡ticamente
4. **Seguridad:** HTTPS automÃ¡tico, backend HTTP interno es seguro

### Costos Estimados

- **Vercel:** $0-20/mes (primeras 2M requests gratis)
- **VMs Google Cloud:** Ya cubierto
- **Total adicional:** ~$0-20/mes

---

## ğŸ“ Soporte

Si encuentras problemas durante el deployment:

1. Verificar logs de Vercel: Dashboard â†’ Deployments â†’ Logs
2. Verificar servicios en VMs: `systemctl status <servicio>`
3. Verificar conectividad: `curl http://IP:PUERTO/health`

---

**Â¡Listo para deployment! ğŸš€**

Las funciones serverless estÃ¡n actualizadas y configuradas segÃºn la arquitectura verificada.
