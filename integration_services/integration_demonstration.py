#!/usr/bin/env python3
"""
Demostraci√≥n de Integraci√≥n Real - Conexi√≥n entre VMs
Conectando el servicio de multimodelos vLLM en models-europe con otros sistemas
"""

import asyncio
import aiohttp
import json
import logging
from typing import Dict, Any
from datetime import datetime

# Configuraci√≥n de logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class NetworkTopology:
    """
    Representaci√≥n de la topolog√≠a de red actual
    """
    def __init__(self):
        self.vms = {
            "models-europe": {
                "name": "models-europe",
                "internal_ip": "10.204.0.9",
                "external_ip": "34.175.48.2",
                "services": {
                    "vllm_multimodel": "http://localhost:8082",  # o http://10.204.0.9:8082
                    "description": "Servidor multimodelos vLLM ARM-Axion"
                }
            },
            "rag-europe": {
                "name": "rag-europe",
                "internal_ip": "10.204.0.10",
                "external_ip": "34.175.110.120",
                "services": {
                    # Sistema RAG principal - bases de datos
                    "milvus": "http://10.204.0.10:19530",    # Base de datos vectorial
                    "nebula_graph": "http://10.204.0.10:9669",  # Base de datos relacional/gr√°fica
                    "postgres": "http://10.204.0.10:5432",     # Base de datos relacional
                    "rag_bridge": "http://10.204.0.10:8000",   # Bridge RAG
                    "description": "Sistema RAG principal (bases de datos vectoriales y relacionales)"
                }
            },
            "services": {
                "name": "services",  # Anteriormente gpt-oss-20b
                "internal_ip": "10.204.0.5",
                "external_ip": "34.175.255.139",  # IP real de la VM services
                "services": {
                    "n8n": "http://10.204.0.5:5678",
                    "nebula_studio": "http://10.204.0.5:7001",
                    "smart_mcp": "http://10.204.0.5:5010",
                    "kyutai_tts": "http://10.204.0.5:5001",
                    "coqui_tts": "http://10.204.0.5:5002",
                    "description": "Servicios de automatizaci√≥n, TTS, MCP y monitoreo"
                }
            }
        }

class IntegrationDemonstrator:
    """
    Demostrador de la integraci√≥n entre los sistemas
    """
    
    def __init__(self):
        self.topology = NetworkTopology()
        self.local_vllm_url = "http://localhost:8082"
    
    async def demonstrate_local_vllm_capabilities(self):
        """
        Demostrar las capacidades del sistema vLLM local
        """
        logger.info("üöÄ Demostrando capacidades de vLLM multimodelos local")
        
        try:
            async with aiohttp.ClientSession() as session:
                # Obtener modelos disponibles
                async with session.get(f"{self.local_vllm_url}/v1/models") as response:
                    models_data = await response.json()
                    available_models = models_data.get("data", [])
                
                print(f"\nü§ñ Modelos disponibles en vLLM local ({self.local_vllm_url}):")
                for model in available_models:
                    print(f"  - {model['id']}: {model.get('description', 'Sin descripci√≥n')}")
                
                # Hacer una prueba de generaci√≥n con cada modelo disponible
                test_query = "Explica en espa√±ol qu√© es Python en una l√≠nea corta."
                
                print(f"\nüí¨ Prueba de generaci√≥n para: '{test_query}'")
                
                for model in available_models[:3]:  # Probar con los primeros 3 modelos
                    model_id = model['id']
                    
                    payload = {
                        "model": model_id,
                        "messages": [{"role": "user", "content": test_query}],
                        "max_tokens": 100,
                        "temperature": 0.7
                    }
                    
                    try:
                        start_time = datetime.now()
                        async with session.post(f"{self.local_vllm_url}/v1/chat/completions", json=payload) as response:
                            if response.status == 200:
                                result = await response.json()
                                response_text = result["choices"][0]["message"]["content"]
                                elapsed_time = (datetime.now() - start_time).total_seconds()
                                
                                print(f"\n  Modelo: {model_id}")
                                print(f"  Respuesta: {response_text[:100]}...")
                                print(f"  Tiempo: {elapsed_time:.2f}s")
                            else:
                                print(f"  ‚ùå Error con modelo {model_id}: {response.status}")
                    except Exception as e:
                        print(f"  ‚ùå Excepci√≥n con modelo {model_id}: {str(e)}")
                        
        except Exception as e:
            logger.error(f"‚ùå Error en demostraci√≥n local: {e}")
    
    async def demonstrate_potential_rag_connection(self):
        """
        Demostrar c√≥mo se conectar√≠a con el sistema RAG en rag-europe
        """
        logger.info("üîó Demostrando conexi√≥n potencial con sistema RAG")
        
        rag_europe_ip = self.topology.vms["rag-europe"]["internal_ip"]
        print(f"\nüì° IP interna de rag-europe: {rag_europe_ip}")
        print("   Esta VM est√° en la misma subred (10.204.0.0/24)")
        print("   Permitiendo comunicaci√≥n interna de alta velocidad")
        
        # Mostrar c√≥mo ser√≠a la conexi√≥n RAG
        rag_endpoints = {
            "bridge": f"http://{rag_europe_ip}:8000",
            "milvus": f"http://{rag_europe_ip}:19530", 
            "nebula_graph": f"http://{rag_europe_ip}:9669",
            "postgres": f"http://{rag_europe_ip}:5432"
        }
        
        print(f"\nüîå Endpoints potenciales para sistema RAG en rag-europe:")
        for service, endpoint in rag_endpoints.items():
            print(f"   {service.upper()}: {endpoint}")
        
        print(f"\nüí° Estrategia de integraci√≥n:")
        print(f"   1. models-europe (10.204.0.9) se comunica con")
        print(f"   2. rag-europe (10.204.0.10) para b√∫squeda de contexto usando:")
        print(f"      - Milvus para b√∫squeda vectorial")
        print(f"      - Nebula Graph para relaciones de conocimiento")
        print(f"      - PostgreSQL para metadatos")
        
        print(f"\nüîÑ Flujo de informaci√≥n:")
        print(f"   Consulta -> models-europe -> rag-europe (Milvus/Nebula) -> contexto -> models-europe -> respuesta")
    
    async def demonstrate_potential_services_connection(self):
        """
        Demostrar c√≥mo se conectar√≠a con servicios distribuidos
        """
        logger.info("üì° Demostrando conexi√≥n potencial con servicios distribuidos")

        # Obtener IPs reales
        rag_europe_internal_ip = self.topology.vms["rag-europe"]["internal_ip"]
        services_internal_ip = self.topology.vms["services"]["internal_ip"]
        services_external_ip = self.topology.vms["services"]["external_ip"]

        print(f"\nüåê Configuraci√≥n real de servicios seg√∫n firewall rules:")
        print(f"   rag-europe ({rag_europe_internal_ip}) tiene servicios:")
        print(f"   - Milvus (base de datos vectorial): http://{rag_europe_internal_ip}:19530")
        print(f"   - Nebula Graph (base de datos gr√°fica): http://{rag_europe_internal_ip}:9669")
        print(f"   - PostgreSQL (base de datos relacional): http://{rag_europe_internal_ip}:5432")
        print(f"   - Bridge RAG: http://{rag_europe_internal_ip}:8000")
        print(f"\n   services ({services_internal_ip}) tiene servicios:")
        print(f"   - N8n (automatizaci√≥n): http://{services_internal_ip}:5678")
        print(f"   - Smart MCP (contexto): http://{services_internal_ip}:5010")
        print(f"   - Nebula Graph Studio (visualizaci√≥n): http://{services_internal_ip}:7001")
        print(f"   - TTS (text-to-speech): http://{services_internal_ip}:5001/5002")

        print(f"\nüéØ Funcionalidades de servicios:")
        print(f"   - Bases de datos (en rag-europe): Milvus (vectorial), Nebula (gr√°fica), PostgreSQL (relacional)")
        print(f"   - MCP (en services): Enriquecimiento de contexto y protocolo de contexto")
        print(f"   - N8n (en services): Automatizaci√≥n de workflows")
        print(f"   - TTS (en services): Conversi√≥n texto-a-voz con Kyutai/Coqui TTS")
        print(f"   - Bridge RAG (en rag-europe): Interface para conexi√≥n con models-europe")
    
    async def demonstrate_complete_integration_flow(self):
        """
        Demostrar el flujo completo de integraci√≥n
        """
        logger.info("üîÑ DEMOSTRACI√ìN COMPLETA: Flujo de integraci√≥n entre sistemas")
        
        print(f"\n{'='*70}")
        print(f"üéØ FLUJO COMPLETO DE INTEGRACI√ìN")
        print(f"{'='*70}")
        
        print(f"1. üìù Usuario env√≠a consulta")
        print(f"   ‚îî‚îÄ‚îÄ> Ej: 'Explica c√≥mo implementar un sistema RAG'")
        
        print(f"\n2. ü§ñ models-europe (vLLM) - Selecci√≥n de modelo √≥ptimo")
        print(f"   ‚îî‚îÄ‚îÄ> Basado en an√°lisis de dominio y complejidad")
        print(f"   ‚îî‚îÄ‚îÄ> Posible: gemma3_multimodal o gptoss_complex")
        
        print(f"\n3. üîç models-europe -> rag-europe - B√∫squeda de contexto")
        print(f"   ‚îî‚îÄ‚îÄ> Solicitud a rag-europe (10.204.0.10:8000)")
        print(f"   ‚îî‚îÄ‚îÄ> B√∫squeda vectorial en Milvus (10.204.0.10:19530)")
        print(f"   ‚îî‚îÄ‚îÄ> An√°lisis relacional en Nebula (10.204.0.10:9669)")
        print(f"   ‚îî‚îÄ‚îÄ> Combinaci√≥n de fuentes de conocimiento")
        
        print(f"\n4. üß† rag-europe -> models-europe - Entrega de contexto enriquecido")
        print(f"   ‚îî‚îÄ‚îÄ> Contexto con fuentes verificadas")
        print(f"   ‚îî‚îÄ‚îÄ> Metadatos y relaciones de conocimiento")
        
        print(f"\n5. üß© models-europe -> services - Enriquecimiento MCP")
        print(f"   ‚îî‚îÄ‚îÄ> Solicitud opcional a MCP (10.204.0.5:5010)")
        print(f"   ‚îî‚îÄ‚îÄ> Mejora de contexto con protocolo de contexto")

        print(f"\n6. ü§ñ models-europe (vLLM) - Generaci√≥n de respuesta final")
        print(f"   ‚îî‚îÄ‚îÄ> Uso de contexto enriquecido")
        print(f"   ‚îî‚îÄ‚îÄ> Aplicaci√≥n de optimizaciones ARM-Axion")
        print(f"   ‚îî‚îÄ‚îÄ> Selecci√≥n del modelo m√°s apropiado")

        print(f"\n7. üéØ Entrega de respuesta detallada al usuario")
        print(f"   ‚îî‚îÄ‚îÄ> Opcional: conversi√≥n a audio v√≠a TTS (10.204.0.5:5001/5002)")
        print(f"   ‚îî‚îÄ‚îÄ> Opcional: automatizaci√≥n v√≠a N8n (10.204.0.5:5678)")
        
        print(f"\nüí° VENTAJAS DE ESTA ARQUITECTURA:")
        print(f"   - Alta velocidad: comunicaci√≥n interna entre VMs en 10.204.0.0/24")
        print(f"   - Seguridad: comunicaci√≥n dentro de la VPC privada de Google Cloud")
        print(f"   - Especializaci√≥n: cada VM optimizada para su funci√≥n espec√≠fica")
        print(f"   - Escalabilidad: servicios pueden escalarse independientemente")
        print(f"   - Resiliencia: fallo en un servicio no detiene completamente el sistema")
        print(f"   - ARM-Axion: optimizaciones espec√≠ficas para rendimiento en ARM")
        
        print(f"{'='*70}")
    
    async def run_complete_demonstration(self):
        """
        Ejecutar la demostraci√≥n completa
        """
        logger.info("üöÄ INICIANDO DEMOSTRACI√ìN COMPLETA DE INTEGRACI√ìN")
        
        print(f"\nüåê TOPOLOG√çA DE RED ACTUAL:")
        print(f"   models-europe: 10.204.0.9 (interna), 34.175.48.2 (externa)")
        print(f"   rag-europe:    10.204.0.10 (interna), 34.175.110.120 (externa)")
        print(f"   services:      10.204.0.5 (interna), 34.175.255.139 (externa) - Anteriormente gpt-oss-20b")
        print(f"\n   ‚úÖ Todas las VMs est√°n en la misma subred (10.204.0.0/24)!")
        print(f"   ‚úÖ Comunicaci√≥n interna de alta velocidad posible entre todas")
        
        # 1. Demostrar capacidades locales
        await self.demonstrate_local_vllm_capabilities()
        
        # 2. Demostrar conexi√≥n potencial RAG
        await self.demonstrate_potential_rag_connection()
        
        # 3. Demostrar conexi√≥n potencial servicios
        await self.demonstrate_potential_services_connection()
        
        # 4. Demostrar flujo completo
        await self.demonstrate_complete_integration_flow()
        
        logger.info("‚úÖ DEMOSTRACI√ìN COMPLETA FINALIZADA")


async def main():
    """
    Funci√≥n principal para ejecutar la demostraci√≥n
    """
    demonstrator = IntegrationDemonstrator()
    await demonstrator.run_complete_demonstration()

if __name__ == "__main__":
    asyncio.run(main())