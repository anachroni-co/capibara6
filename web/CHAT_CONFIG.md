# Configuraci√≥n del Chat - Capibara6

> üü° **MODO BETA**: El sistema Capibara6 Consensus est√° actualmente en fase beta.

## Conexi√≥n con el Servidor

El chat est√° configurado para conectarse con un servidor de inferencia que ejecuta Capibara6.

### URL del Servidor
```
http://34.175.89.158:8080/completion
```

### Par√°metros Configurados

```javascript
{
  "prompt": "<bos><start_of_turn>system\nResponde en el mismo idioma de la pregunta. Si piden c√≥digo, usa bloques markdown: \`\`\`lenguaje<end_of_turn>\n<start_of_turn>user\n{mensaje}<end_of_turn>\n<start_of_turn>model\n",
  "n_predict": 100,           // Respuestas cortas y enfocadas
  "temperature": 0.6,         // Balanceado
  "top_p": 0.85,             // Ligeramente reducido
  "repeat_penalty": 1.3,     // Evita repeticiones sin ser excesivo
  "stream": true,            // Streaming activado
  "stop": ["<end_of_turn>", "<|im_end|>", "\n```", "html<!DOCTYPE", "html<", "php<", "js<", "{-", "<audio", "<video"]
}
```

### System Prompt

El chat incluye autom√°ticamente un **system prompt** mejorado que evita respuestas antropom√≥rficas incorrectas:

```
Tu nombre es Capibara6. Responde de forma breve y precisa.
```

**Filosof√≠a MINIMALISTA para Gemma 3:**
- ‚úÖ Ultra corto (10 palabras) - imposible de citar
- ‚úÖ Solo lo esencial: nombre + comportamiento
- ‚úÖ Lenguaje directo sin listas ni formatos
- ‚úÖ El modelo no tiene nada que copiar o repetir

**Por qu√© tan simple:**
Los prompts largos con Gemma 3 tienden a ser citados por el modelo en lugar de seguirlos. 
Un prompt minimalista evita este problema completamente.

**Par√°metros OPTIMIZADOS y BALANCEADOS:**
- `n_predict: 100` - Respuestas cortas y al punto
- `temperature: 0.6` - Balanceado (ni muy creativo ni muy r√≠gido)
- `top_p: 0.85` - Ligeramente reducido
- `repeat_penalty: 1.3` - Evita repeticiones sin bloquear
- **Streaming**: Activado para respuestas en tiempo real
- **Stops especiales**: Para evitar c√≥digo duplicado y tokens extra√±os
  - `"\n```"` - Detiene despu√©s de bloques de c√≥digo
  - `"html<!DOCTYPE"`, `"html<"`, `"php<"` - Evita tokens malformados
  - `"<audio"`, `"<video"` - Evita metadata multimedia
  - `"<|im_end|>"` - Token de fin est√°ndar

**Estad√≠sticas mostradas (6 valores informativos):**
- ‚è±Ô∏è **Tiempo**: Duraci√≥n de generaci√≥n
- üí¨ **Tokens Gen**: Tokens generados por el modelo
- ‚û°Ô∏è **Tokens In**: Tokens del prompt (entrada)
- üìö **Total**: Tokens totales procesados
- ‚ö° **Velocidad**: Tokens/segundo
- üñ•Ô∏è **Modelo**: capibara6

Este prompt puede modificarse en `chat-app.js` l√≠nea 8.

### Ejemplos de Respuestas Correctas

‚ùå **INCORRECTO:**
```
Usuario: ¬øCu√°l es la capital de Italia?
Capibara6: La capital de Italia es Roma. Puedes encontrar m√°s detalles 
en Wikipedia (https://it.wikipedia.org/wiki/Roma). ¬øHay algo m√°s en lo 
que pueda ayudarte? Puedes buscar informaci√≥n sobre otros pa√≠ses...
```

‚úÖ **CORRECTO:**
```
Usuario: ¬øCu√°l es la capital de Italia?
Capibara6: La capital de Italia es Roma.
```

‚ùå **INCORRECTO:**
```
Usuario: ¬øQu√© haces en tu tiempo libre?
Capibara6: En mi tiempo libre disfruto de aprender sobre IA...
```

‚úÖ **CORRECTO:**
```
Usuario: ¬øQu√© haces en tu tiempo libre?
Capibara6: Soy un modelo de IA, no tengo tiempo libre.
```

### Modificar Configuraci√≥n

Para cambiar la URL o los par√°metros, edita el archivo `chat-app.js`:

```javascript
// Configuraci√≥n del modelo (l√≠neas 5-18)
const MODEL_CONFIG = {
    serverUrl: 'http://34.175.89.158:8080/completion',
    systemPrompt: `Tu nombre es Capibara6. Responde de forma breve y precisa.`,
    defaultParams: {
        n_predict: 512,
        temperature: 0.6,
        top_p: 0.9,
        repeat_penalty: 1.1,
        presence_penalty: 0.2,
        frequency_penalty: 0.2,
        stop: ["<end_of_turn>", "\n\n\n"]
    }
};
```

### Ejemplo de Request

**Mensaje simple:**
```bash
curl http://34.175.89.158:8080/completion -d '{
  "prompt": "<bos><start_of_turn>user\nDescribe qu√© es la inteligencia artificial.<end_of_turn>\n<start_of_turn>model\n",
  "n_predict": 128,
  "temperature": 0.6,
  "top_p": 0.9,
  "repeat_penalty": 1.1,
  "presence_penalty": 0.2,
  "frequency_penalty": 0.2
}'
```

**Conversaci√≥n con historial y system prompt:**
```bash
curl http://34.175.89.158:8080/completion -d '{
  "prompt": "<bos><start_of_turn>system\nEres Capibara6, un asistente de IA creado por Anachroni s.coop. Eres √∫til, conciso y preciso. Responde solo lo necesario, en el idioma del usuario. Evita repetir la pregunta y limita tus respuestas a 3 p√°rrafos como m√°ximo. Cuando te pregunten qui√©n eres, di que te llamas Capibara6 y fuiste creado por Anachroni s.coop.<end_of_turn>\n<start_of_turn>user\n¬øCu√°l es la capital de Espa√±a?<end_of_turn>\n<start_of_turn>model\nMadrid.<end_of_turn>\n<start_of_turn>user\n¬øY de Italia?<end_of_turn>\n<start_of_turn>model\n",
  "n_predict": 64
}'
```

El chat **autom√°ticamente**:
- Agrega el system prompt al inicio
- Construye el historial completo de la conversaci√≥n
- Mantiene el contexto en cada request

### Formato de Respuesta

El servidor retorna un JSON con la siguiente estructura:

```json
{
  "content": "respuesta del modelo...",
  "tokens_predicted": 88,
  "stop": true,
  "model": "gpt-3.5-turbo",
  ...
}
```

## Caracter√≠sticas Implementadas

‚úÖ Conexi√≥n directa con Capibara6  
‚úÖ Manejo de errores con mensajes amigables  
‚úÖ Indicador de escritura mientras genera  
‚úÖ Soporte para archivos adjuntos (hasta 10MB)  
‚úÖ Historial de conversaciones  
‚úÖ Interfaz estilo ChatGPT  

## CORS

**Importante:** El servidor debe tener CORS habilitado para permitir peticiones desde el navegador.

Si encuentras errores de CORS, necesitar√°s configurar el servidor o usar un proxy.

## Soluci√≥n de Problemas

### Error de CORS
Si ves errores de CORS en la consola del navegador, el servidor necesita agregar estos headers:

```
Access-Control-Allow-Origin: *
Access-Control-Allow-Methods: POST, GET, OPTIONS
Access-Control-Allow-Headers: Content-Type
```

### Servidor no responde
Verifica que el servidor est√© activo:

```bash
curl http://34.175.89.158:8080/completion -d '{"prompt":"test","n_predict":10}'
```

### Timeout
Si las respuestas tardan mucho, reduce `n_predict` a un valor menor (ej: 256).

## Desarrollo Local

Para probar localmente con un servidor diferente:

1. Modifica `MODEL_CONFIG.serverUrl` en `chat-app.js`
2. Aseg√∫rate de que el servidor est√© corriendo
3. Abre `chat.html` en tu navegador

## Producci√≥n

Para producci√≥n, considera:

- Usar HTTPS en lugar de HTTP
- Implementar autenticaci√≥n
- Agregar rate limiting
- Configurar un proxy inverso (nginx/Apache)

