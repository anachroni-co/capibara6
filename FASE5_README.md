# FASE 5: Metadata System - Sistema Completo de Captura y Procesamiento de M√©tricas

## üéØ Objetivo

Implementar el sistema completo de metadata que incluye:
- **Captura completa** de m√©tricas de todos los componentes del sistema
- **TimescaleDB** con esquemas optimizados y compresi√≥n autom√°tica
- **Pipeline de agregaci√≥n** diaria con m√©tricas derivadas
- **Detecci√≥n de anomal√≠as** autom√°tica con alertas
- **Reportes semanales** y dashboards de monitoreo
- **Integraci√≥n completa** con todos los componentes del sistema

## üìã Componentes Implementados

### 1. üìä Metrics Collector (`backend/metadata/metrics_collector.py`)

**Sistema de Recolecci√≥n de M√©tricas:**
- **8 tipos de m√©tricas**: Routing, Memory, Attention, Compute, Execution, Agent Evolution, RAG, System
- **Buffer circular** con l√≠mite configurable (10,000 m√©tricas por defecto)
- **Flush autom√°tico** cada 30 segundos
- **Threading as√≠ncrono** para no bloquear el sistema principal
- **Manejo de errores** robusto con estad√≠sticas

**Tipos de M√©tricas Implementadas:**
- **RoutingMetrics**: Complejidad, confianza, modelo seleccionado, tiempo de routing
- **MemoryMetrics**: Operaciones de memoria, compresi√≥n, cache hits, importancia
- **AttentionMetrics**: Patrones de atenci√≥n, entrop√≠a, diversidad, tiempo de c√≥mputo
- **ComputeMetrics**: Utilizaci√≥n GPU/CPU, throughput, latencia, tokens procesados
- **ExecutionMetrics**: Ejecuci√≥n E2B, correcciones, errores, tiempo de ejecuci√≥n
- **AgentEvolutionMetrics**: Evoluci√≥n de agentes, graduaci√≥n, expertise, colaboraciones
- **RAGMetrics**: Retrieval, relevancia, documentos, tiempo de b√∫squeda
- **SystemMetrics**: CPU, memoria, disco, conexiones, throughput del sistema

**Caracter√≠sticas:**
- **Buffer thread-safe** con queue.Queue
- **Flush worker** en thread separado
- **Estad√≠sticas detalladas** de recolecci√≥n
- **Manejo de overflow** del buffer
- **M√©tricas compuestas** y simples

### 2. üîó Metrics Integration (`backend/metadata/metrics_integration.py`)

**Integraci√≥n con Todos los Componentes:**
- **Context managers** para tracking autom√°tico
- **Decoradores** para m√©tricas de funciones
- **Integraci√≥n transparente** con el c√≥digo existente
- **Tracking autom√°tico** de tiempo y recursos

**Integraciones Implementadas:**
- **Routing**: Tracking de decisiones de routing con contexto
- **Memory**: Operaciones de lectura/escritura con cache hits
- **Compute**: Inferencia de modelos con m√©tricas de GPU/CPU
- **Execution**: Ejecuci√≥n E2B con correcciones y errores
- **Agent Evolution**: Creaci√≥n, entrenamiento, graduaci√≥n de agentes
- **RAG**: Retrieval con relevancia y tiempo de b√∫squeda
- **System**: M√©tricas del sistema operativo y aplicaci√≥n

**Context Managers:**
```python
# Tracking de routing
with integration.track_routing("query_001", "Python optimization", "optimization"):
    # C√≥digo de routing
    pass

# Tracking de memoria
with integration.track_memory_read("agent_001", "knowledge") as cache_hit:
    # C√≥digo de lectura de memoria
    pass

# Tracking de c√≥mputo
with integration.track_model_inference("120B", batch_size=1) as (tokens, seq_len):
    # C√≥digo de inferencia
    pass
```

### 3. üóÑÔ∏è TimescaleDB Manager (`backend/metadata/timescaledb_manager.py`)

**Gesti√≥n Completa de TimescaleDB:**
- **7 tablas de m√©tricas** con esquemas optimizados
- **Hypertables** para escalabilidad temporal
- **Compresi√≥n autom√°tica** configurable por tabla
- **√çndices optimizados** para consultas r√°pidas
- **Pol√≠ticas de retenci√≥n** autom√°ticas

**Esquemas de Tablas:**
```sql
-- Routing Metrics
CREATE TABLE metrics.routing_metrics (
    time TIMESTAMPTZ NOT NULL,
    query_id TEXT,
    complexity_score REAL,
    confidence_score REAL,
    model_selected TEXT,
    routing_time_ms INTEGER,
    -- ... m√°s campos
);

-- Memory Metrics
CREATE TABLE metrics.memory_metrics (
    time TIMESTAMPTZ NOT NULL,
    agent_id TEXT,
    memory_type TEXT,
    memory_operation TEXT,
    memory_size_bytes BIGINT,
    -- ... m√°s campos
);

-- Compute Metrics
CREATE TABLE metrics.compute_metrics (
    time TIMESTAMPTZ NOT NULL,
    model_id TEXT,
    operation_type TEXT,
    gpu_utilization_percent REAL,
    throughput_tokens_per_sec REAL,
    -- ... m√°s campos
);
```

**Pol√≠ticas de Compresi√≥n:**
- **Routing/Memory/Compute/Execution/RAG**: 30 d√≠as
- **System Metrics**: 7 d√≠as (m√°s frecuente)
- **Compresi√≥n autom√°tica** con TimescaleDB
- **Retenci√≥n configurable** por tipo de m√©trica

**Caracter√≠sticas:**
- **Conexi√≥n autom√°tica** con reintentos
- **Verificaci√≥n de extensi√≥n** TimescaleDB
- **Creaci√≥n autom√°tica** de hypertables
- **Inserci√≥n en lote** para eficiencia
- **Consultas optimizadas** con √≠ndices

### 4. üîÑ Metrics Pipeline (`backend/metadata/metrics_pipeline.py`)

**Pipeline de Procesamiento de M√©tricas:**
- **Agregaci√≥n diaria** autom√°tica
- **M√©tricas derivadas** calculadas
- **Detecci√≥n de anomal√≠as** en tiempo real
- **Reportes autom√°ticos** generados

**Agregaciones Implementadas:**
- **Por tabla**: Routing, Memory, Compute, Execution, RAG, System
- **Por tiempo**: 1 hora, 1 d√≠a, 1 semana
- **Por m√©trica**: avg, sum, min, max, count, p50, p95, p99
- **Por grupo**: modelo, agente, dominio, tipo de operaci√≥n

**M√©tricas Derivadas:**
- **System Health Score**: 100 - (CPU + Memory + Error Rate) / 3
- **Agent Efficiency Score**: Success Rate √ó (1000 / Execution Time)
- **Routing Accuracy Score**: Confidence √ó (1 - |Complexity - 0.7|)

**Detecci√≥n de Anomal√≠as:**
- **Spikes**: Valores por encima del umbral
- **Drops**: Valores por debajo del umbral
- **Trend Changes**: Cambios en tendencias
- **Outliers**: Valores at√≠picos estad√≠sticamente

**Configuraci√≥n de Anomal√≠as:**
```python
anomaly_configs = {
    'system_metrics.cpu_usage_percent.avg': {
        'threshold': 80.0,
        'anomaly_type': 'spike',
        'severity': 'high'
    },
    'system_metrics.memory_usage_percent.avg': {
        'threshold': 90.0,
        'anomaly_type': 'spike',
        'severity': 'critical'
    }
}
```

### 5. üèóÔ∏è Metadata System (`backend/metadata/metadata_system.py`)

**Sistema Completo de Metadata:**
- **Integraci√≥n unificada** de todos los componentes
- **API centralizada** para tracking de m√©tricas
- **Health checks** autom√°ticos
- **Gesti√≥n de estado** del sistema
- **Instancia global** para uso en toda la aplicaci√≥n

**API Principal:**
```python
# Inicializar sistema
metadata_system = MetadataSystem()
await metadata_system.initialize()
await metadata_system.start()

# Tracking de m√©tricas
metadata_system.track_routing_decision(
    "query_001", 0.8, 0.9, "120B", 50, "python"
)

metadata_system.track_memory_operation(
    "agent_001", "knowledge", "write", 1024, 256, 10
)

metadata_system.track_compute_operation(
    "120B", "inference", 1, 1000, 1000, 2000, 85.0, 8000.0
)

# Health check
health = await metadata_system.health_check()

# Estad√≠sticas
stats = metadata_system.get_system_stats()
```

**Sistema Global:**
```python
# Inicializar sistema global
metadata_system = initialize_metadata_system()
await start_metadata_system()

# Usar en cualquier parte de la aplicaci√≥n
global_system = get_metadata_system()
global_system.track_system_metrics(cpu_usage_percent=25.0)

# Detener sistema
await stop_metadata_system()
```

## üöÄ Configuraci√≥n y Uso

### Configuraci√≥n de TimescaleDB

```bash
# Instalar TimescaleDB
sudo apt-get install timescaledb-2-postgresql-14

# Crear base de datos
createdb capibara6_metrics

# Conectar y configurar
psql capibara6_metrics
CREATE EXTENSION IF NOT EXISTS timescaledb;
```

### Variables de Entorno

```bash
# TimescaleDB
export TIMESCALEDB_HOST=localhost
export TIMESCALEDB_PORT=5432
export TIMESCALEDB_DATABASE=capibara6_metrics
export TIMESCALEDB_USERNAME=postgres
export TIMESCALEDB_PASSWORD=password

# Metrics Collector
export METRICS_BUFFER_SIZE=10000
export METRICS_FLUSH_INTERVAL=30
export ENABLE_SYSTEM_METRICS=true
```

### Uso B√°sico

```python
from backend.metadata.metadata_system import initialize_metadata_system, start_metadata_system

# Inicializar sistema
metadata_system = initialize_metadata_system()
await start_metadata_system()

# El sistema est√° listo para usar
```

### Integraci√≥n con Componentes Existentes

```python
# En el router
from backend.metadata.metadata_system import get_metadata_system

def route_query(query, complexity, confidence):
    metadata_system = get_metadata_system()
    
    start_time = time.time()
    model = select_model(complexity, confidence)
    routing_time = int((time.time() - start_time) * 1000)
    
    # Track m√©tricas
    metadata_system.track_routing_decision(
        query_id=generate_id(),
        complexity_score=complexity,
        confidence_score=confidence,
        model_selected=model,
        routing_time_ms=routing_time
    )
    
    return model

# En el agente
def process_query(agent_id, query):
    metadata_system = get_metadata_system()
    
    # Track evoluci√≥n del agente
    metadata_system.track_agent_evolution(
        agent_id=agent_id,
        domain="python",
        evolution_event="interaction",
        interactions_count=1,
        success_rate=0.8,
        graduation_score=0.7
    )
```

## üìä M√©tricas y Monitoreo

### M√©tricas de Routing
- Tiempo de routing (p50, p95, p99)
- Complejidad promedio por dominio
- Confianza promedio por modelo
- Distribuci√≥n de modelos seleccionados
- Tasa de √©xito de routing

### M√©tricas de Memoria
- Operaciones de memoria por agente
- Tasa de cache hit por tipo
- Compresi√≥n de memoria por agente
- Utilizaci√≥n de memoria por dominio
- Tiempo de operaciones de memoria

### M√©tricas de C√≥mputo
- Utilizaci√≥n GPU/CPU por modelo
- Throughput de tokens por segundo
- Latencia de inferencia (p50, p95, p99)
- Memoria GPU utilizada
- Eficiencia de c√≥mputo

### M√©tricas de Ejecuci√≥n E2B
- Tasa de √©xito por lenguaje
- Tiempo de ejecuci√≥n promedio
- Correcciones aplicadas por agente
- Errores m√°s comunes
- Utilizaci√≥n de recursos

### M√©tricas de Evoluci√≥n de Agentes
- Tasa de graduaci√≥n por dominio
- Score de graduaci√≥n promedio
- Interacciones por agente
- Expertise por dominio
- Colaboraciones exitosas

### M√©tricas de RAG
- Tiempo de retrieval por tipo
- Relevancia de documentos
- Estrategias de b√∫squeda m√°s efectivas
- Contexto generado por query
- Eficiencia de b√∫squeda

### M√©tricas del Sistema
- CPU, memoria, disco utilizados
- Conexiones activas
- Throughput de requests
- Tasa de errores
- Tiempo de respuesta promedio

## üîß Configuraci√≥n Avanzada

### Personalizaci√≥n de Agregaciones

```python
# Configurar agregaciones personalizadas
aggregator = MetricsAggregator(timescaledb_manager)

# Agregar nueva configuraci√≥n
aggregator.aggregation_configs['custom_metrics'] = {
    'aggregations': ['avg', 'p95', 'p99'],
    'group_by': ['custom_field'],
    'time_buckets': ['1 hour', '1 day'],
    'metrics': ['custom_metric']
}
```

### Configuraci√≥n de Anomal√≠as

```python
# Personalizar detecci√≥n de anomal√≠as
anomaly_configs = {
    'custom_metric.avg': {
        'threshold': 100.0,
        'anomaly_type': 'spike',
        'severity': 'medium'
    }
}

# Agregar al pipeline
pipeline.aggregator.anomaly_configs.update(anomaly_configs)
```

### Pol√≠ticas de Compresi√≥n

```python
# Configurar compresi√≥n personalizada
timescaledb_manager.compression_policies = {
    'routing_metrics': 15,  # 15 d√≠as
    'memory_metrics': 45,   # 45 d√≠as
    'system_metrics': 3     # 3 d√≠as
}
```

## üß™ Testing

### Tests Unitarios
```bash
# Ejecutar tests de FASE 5
python backend/test_fase5.py
```

### Tests Espec√≠ficos
```python
# Test de collector
python -c "from backend.test_fase5 import test_metrics_collector; test_metrics_collector()"

# Test de integraci√≥n
python -c "from backend.test_fase5 import test_metrics_integration; test_metrics_integration()"

# Test de pipeline
python -c "import asyncio; from backend.test_fase5 import test_metrics_pipeline; asyncio.run(test_metrics_pipeline())"
```

### Tests de Integraci√≥n
```python
# Test completo del sistema
metadata_system = MetadataSystem()
await metadata_system.initialize()
await metadata_system.start()

# Simular m√©tricas
metadata_system.track_routing_decision("test_001", 0.8, 0.9, "120B", 50)
metadata_system.track_system_metrics(cpu_usage_percent=25.0)

# Verificar health
health = await metadata_system.health_check()
assert health['status'] == 'healthy'
```

## üìÅ Estructura de Archivos

```
backend/metadata/
‚îú‚îÄ‚îÄ __init__.py              # Inicializaci√≥n del m√≥dulo
‚îú‚îÄ‚îÄ metrics_collector.py     # Recolecci√≥n de m√©tricas
‚îú‚îÄ‚îÄ metrics_integration.py   # Integraci√≥n con componentes
‚îú‚îÄ‚îÄ timescaledb_manager.py   # Gesti√≥n de TimescaleDB
‚îú‚îÄ‚îÄ metrics_pipeline.py      # Pipeline de procesamiento
‚îî‚îÄ‚îÄ metadata_system.py       # Sistema completo

backend/test_fase5.py        # Tests completos de FASE 5
```

## üéØ Pr√≥ximos Pasos (FASE 6)

1. **Fine-tuning Pipeline** - Consolidaci√≥n de playbooks y datasets
2. **LoRA/QLoRA** - Configuraci√≥n de fine-tuning eficiente
3. **Distributed Training** - Entrenamiento distribuido en TPU
4. **Evaluation Benchmarks** - HumanEval, MMLU, AppWorld
5. **A/B Testing Framework** - Testing y rollback autom√°tico

## üìä Estado Actual

‚úÖ **Completado:**
- Metrics Collector con 8 tipos de m√©tricas
- Metrics Integration con context managers
- TimescaleDB Manager con 7 tablas optimizadas
- Metrics Pipeline con agregaci√≥n y anomal√≠as
- Metadata System completo con API unificada
- Tests completos y documentaci√≥n

üîÑ **En Progreso:**
- Configuraci√≥n de TimescaleDB en producci√≥n
- Dashboards de Grafana
- Alertas autom√°ticas

üìã **Pendiente:**
- Fine-tuning Pipeline (FASE 6)
- Evaluation Benchmarks (FASE 6)
- Advanced Optimizations (FASE 7)
- Production Deployment (FASE 8)

## ü§ù Contribuci√≥n

Para contribuir al sistema de metadata:

1. Fork del repositorio
2. Crear branch para feature
3. Implementar cambios con tests
4. Crear Pull Request

## üìÑ Licencia

Este proyecto est√° bajo la licencia MIT. Ver `LICENSE` para m√°s detalles.

---

**FASE 5 completada exitosamente** üéâ

El sistema de metadata est√° listo para la integraci√≥n con el Fine-tuning Pipeline en la FASE 6.
