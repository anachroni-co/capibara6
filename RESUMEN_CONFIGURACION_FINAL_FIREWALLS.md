# ğŸ”¥ ConfiguraciÃ³n Final de Firewalls - Capibara6

## ğŸ“‹ Resumen de Puertos por VM

### VM: **bounty2** (34.12.166.76)
**Puertos abiertos externamente**:
- âœ… **5000** - Capibara6 Integrated Server
- âœ… **5002** - Coqui TTS Server
- âœ… **8080** - Gemma Model Server / CapibaraGPT-v2 GUI
- âœ… **7001** - Nebula Graph Studio
- âœ… **80** - HTTP
- âœ… **22** - SSH

**Puertos NO abiertos externamente**:
- âŒ **5001** - Backend Flask (usar 5000 en su lugar)
- âŒ **11434** - Ollama API (solo acceso interno 10.0.0.0/8)

**Puertos internos/TPU**:
- ğŸ”’ **8470** - TPU interno (solo 10.0.0.0/8)
- ğŸ”’ **9230** - TPU healthcheck (rangos Google)
- ğŸ”’ **12355** - TPU coordination (solo 10.128.0.0/20)

### VM: **gpt-oss-20b** (34.175.136.104)
**Puertos abiertos externamente**:
- âœ… **5000** - Capibara6 Main Server
- âœ… **5001** - Kyutai TTS Server
- âœ… **5003** - Smart MCP Server
- âœ… **8080** - Gemma Model Server / CapibaraGPT-v2 GUI
- âœ… **80** - HTTP
- âœ… **443** - HTTPS
- âœ… **22** - SSH
- âœ… **7001** - Nebula Graph Studio

**Puertos NO abiertos**:
- âŒ **5002** - TTS (usar 5001 en su lugar)
- âŒ **5010** - MCP alternativo (usar 5003 en su lugar)
- âŒ **5678** - N8n (necesita regla de firewall)

### VM: **rag3** (IP a obtener)
**Puertos abiertos externamente**:
- âœ… **5000** - Capibara6 Integrated Server
- âœ… **5001** - Kyutai TTS Server
- âœ… **8080** - llama.cpp Server / CapibaraGPT-v2 GUI
- âœ… **11434** - Ollama API
- âœ… **443** - HTTPS
- âœ… **22** - SSH
- âœ… **7001** - Nebula Graph Studio

**Puertos NO abiertos**:
- âŒ **8000** - RAG API (usar 5000 en su lugar o aÃ±adir regla)

## ğŸ”§ ConfiguraciÃ³n Actualizada

### Backend Principal
- **bounty2**: Puerto **5000** âœ… (actualizado de 5001)
- Proxy CORS: `http://localhost:8001` â†’ `http://34.12.166.76:5000`

### Ollama
- **NO accesible externamente** desde el frontend
- Solo accesible internamente (10.0.0.0/8) o a travÃ©s del backend integrado
- El backend en puerto 5000 puede acceder a Ollama internamente

### TTS
- **bounty2**: Puerto **5002** (Coqui TTS Server) âœ…
- **gpt-oss-20b**: Puerto **5001** (Kyutai TTS Server) âœ…

### MCP
- **gpt-oss-20b**: Puerto **5003** (Smart MCP Server) âœ…
- **Backend integrado**: A travÃ©s de bounty2:5000 (integrado) âœ…

### RAG API
- **rag3**: Puerto **5000** (temporal, hasta abrir 8000) âš ï¸

### N8n
- **gpt-oss-20b**: Puerto **5678** NO estÃ¡ abierto âš ï¸
- Necesita regla de firewall o verificar puerto alternativo

## âœ… Cambios Realizados

1. âœ… **backend/cors_proxy_simple.py**: Actualizado a puerto 5000
2. âœ… **web/config.js**: 
   - Ollama marcado como no accesible externamente
   - RAG API actualizado a puerto 5000
   - TTS en gpt-oss-20b actualizado a puerto 5001
3. âœ… **web/smart-mcp-integration.js**: Comentarios actualizados

## ğŸ“ PrÃ³ximos Pasos

1. âš ï¸ **Verificar que el backend estÃ¡ corriendo en puerto 5000** en bounty2
2. âš ï¸ **AÃ±adir regla de firewall para N8n** (puerto 5678) en gpt-oss-20b
3. âš ï¸ **AÃ±adir regla de firewall para RAG API** (puerto 8000) en rag3, o confirmar que usa 5000
4. âš ï¸ **Obtener IP externa de rag3** y actualizar configuraciÃ³n

## ğŸ¯ Notas Importantes

- **Ollama NO es accesible directamente** desde el frontend. Debe usarse a travÃ©s del backend integrado.
- El **backend principal** debe estar en **puerto 5000**, no 5001.
- **TTS** usa diferentes puertos segÃºn la VM: 5002 en bounty2, 5001 en gpt-oss-20b.

